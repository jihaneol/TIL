# 1장 인공지능
인공지능 - 머신러닝 - 딥러닝

## 머신 러닝은 기계학습
스스로 규칙을 수정

### 지도 학습
입력과 타깃으로 모델을 훈련

### 비지도 학습
타깃이 없는 데이터를 사용<br>
대표적으로 군집이 있다.

### 강화 학습
주어진 환경으로부터 피드백을 받아 훈련

## 딥러닝
머신러닝 알고리즘 중 하나인 인공신경망으로 만든 것

### 딥러닝은 머신러닝이 처리하기 어려운 데이터를 더 잘 처리한다.

딥러닝 : 이미지, 음성, 텍스트

머신러닝 : 데이터베이스, 엑셀, 레코드 파일

# 2장 딥러닝 도구
## 넘파이
다차원 배열을 다루기 위해 사용한다. 기본 배열 보다 성능이 좋다
## 맷플롯립
그래프 패키지

---

# 3장 머신러닝 기초
선형 회귀는 기울기와 절편을 찾아준다.

## 01. 데이터 준비하기

diabetes.data[:, 0]    # 첫 번째 열만 가져옴 (모든 행, 0번 열)

diabetes.data[0, :]    # 첫 번째 행만 가져옴 (0번 행, 모든 열)

diabetes.data[:,]      # 모든 행, 모든 열 == diabetes.data

## 02. 경사 하강법
데이터와 타깃 데이터를 통해 기울기와 절편을 찾는 것이 선형 회귀의 목표다.

경사 하강법은 기울기(변화율)를 사용하여 모델을 조금씩 조정하는 최적화 알고리즘이다.

문제점
1. y_hat이 y에 한참 미치지 못할 때 , w b를 대폭 수정 못한다.
2. y_hat이 y보다 커지면 y_hat을 감소시키지 못 한다.

### 오차 역전파로 가중치와 절편을 더 적절하게 업데이트
오차가 연이어 전파되는 모습으로 수행된다.

1. 오차와 변화율을 곱하여 가중치 업데이트
2. 두 번째 샘플을 사용하여 가중치 업데이트
3. 전체 샘플 반복
4. 과정 3을 통해 얻어낸 모델을 확인
5. 여러 에포크를 반복하기

## 03. 손실 함수와 경사 하강법의 관계
경사 하강법 : 어떤 손실 함수가 정의되었을 때 손실 함수의 값이 최소가 되는 지점

손실 함수 : 예상한 값과 실제 타깃값의 차이를 함수로 정의한 것

앞에서 사용했던 '오차를 변화율에 곱하여 가중치와 절편 업데이트 하기'는 '제곱 오차'라는 손실 함수를 미분
한 것과 같다.

변화율은 인공지능 분야에서 특별히 그레이디언트(경사)라고 부른다.

## 04. 선형 회귀를 위한 뉴런을 만듭니다.
### 정방향 계산
예측값을 구한다.
### 역방향 계산
예측값 - 결과값의 음수, 곧 미분한것의 음수

오차가 역전파됩니다.

손실함수를 미분하여 w,b를 구해 최적을 구하는 거다.

---

# 4장 분류하는 뉴런 - 이진 분류

## 01. 로지스틱 회귀
### 퍼셉트론
1957년에 이진 분류 문제에서 최적의 가중치를 학습하는 퍼셉트론알고리즘 발표

선형 회귀와 유사한 구조지만 샘플을 이진 분류하기 위하여 계단 함수라는 것을 사용합니다.

계단 함수를 통과한 값을 다시 가중치와 절편을 업데이트하는데 사용한다.

선형함수 : wx1 + wx2 + b = z

### 아달린
1960년에 퍼셉트론을 개선한 적응형 선형 뉴런을 발표 -> 아달린

선형 함수의 결과를 학습에 사용한다. 게단 함수의 결과는 예측에만 활용한다.

### 로지스틱 회귀
아달린에서 조금 더 발전한 형태

선형 함수를 통과시켜 얻은 z를 임계 함수에 보내기 전에 변형시키는데, 바로 <br>
이런 함수를 활성화 함수라고 부른다.

활성화 함수를 통과한 값 a라고 하자

마지막 단계에서 임계 함수를 사용하여 예측을 수행한다.

**임계함수는 계단함수의 일종**

#### - 활성화 함수는 비선형 함수를 사용한다.
선형 함수를 사용하면 임계 함수앞에 뉴런을 여러 개 쌓아도 결국 선형 함수일 것이므로 의미가 없기 때문이다.

로지스틱 회귀의 활성화 함수는 '시그모이드 함수'이다.

## 02. 시그모이드 함수로 확률을 만듭니다.
선형 함수 z -> 활성화 함수 a -> 임계함수 예측값

시그모이드 함수는 z를 0~1 사이의 확률값으로 변환 시켜주는 역할을 한다.

### 시스모이드 함수가 만들어지는 과정
오즈 비 > 로짓 함수 > 시그모이드 함수

오즈 비: 성공 확률과 실패 확률의 비율을 나타내는 통계이다.

로짓 함수: 오즈 비에 로그 함수를 취한것

로지스틱 함수: 시그모이드 함수, 확률 p가 y축으로 정리한것, z에 대해서 정리

## 03. 로지스틱 손실 함수를 경사 하강법에 적용
