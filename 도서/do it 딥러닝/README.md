# 1장 인공지능
인공지능 - 머신러닝 - 딥러닝

## 머신 러닝은 기계학습
스스로 규칙을 수정

### 지도 학습
입력과 타깃으로 모델을 훈련

### 비지도 학습
타깃이 없는 데이터를 사용<br>
대표적으로 군집이 있다.

### 강화 학습
주어진 환경으로부터 피드백을 받아 훈련

## 딥러닝
머신러닝 알고리즘 중 하나인 인공신경망으로 만든 것

### 딥러닝은 머신러닝이 처리하기 어려운 데이터를 더 잘 처리한다.

딥러닝 : 이미지, 음성, 텍스트

머신러닝 : 데이터베이스, 엑셀, 레코드 파일

# 2장 딥러닝 도구
## 넘파이
다차원 배열을 다루기 위해 사용한다. 기본 배열 보다 성능이 좋다
## 맷플롯립
그래프 패키지

# 3장 머신러닝 기초
션형 회귀는 기울기와 절편을 찾아준다.

## 01. 데이터 준비하기

diabetes.data[:, 0]    # 첫 번째 열만 가져옴 (모든 행, 0번 열)

diabetes.data[0, :]    # 첫 번째 행만 가져옴 (0번 행, 모든 열)

diabetes.data[:,]      # 모든 행, 모든 열 == diabetes.data

## 02. 경사 하강법
데이터와 타깃 데이터를 통해 기울기와 절편을 찾는 것이 선형 회귀의 목표다.

경사 하강법은 기울기(변화율)를 사용하여 모델을 조금씩 조정하는 최적화 알고리즘이다.

문제점
1. y_hat이 y에 한참 미치지 못할 때 , w b를 대폭 수정 못한다.
2. y_hat이 y보다 커지면 y_hat을 감소시키지 못 한다.

### 오차 역전파로 가중치와 절편을 더 적절하게 업데이트
오차가 연이어 전파되는 모습으로 수행된다.

1. 오차와 변화율을 곱하여 가중치 업데이트
2. 두 번째 샘플을 사용하여 가중치 업데이트
3. 전체 샘플 반복
4. 과정 3을 통해 얻어낸 모델을 확인
5. 여러 에포크를 반복하기

## 03. 손실 함수와 경사 하강법의 관계
경사 하강법 : 어떤 손실 함수가 정의되었을 때 손실 함수의 값이 최소가 되는 지점

손실 함수 : 예상한 값과 실제 타깃값의 차이를 함수로 정의한 것

앞에서 사용했던 '오차를 변화율에 곱하여 가중치와 절편 업데이트 하기'는 '제곱 오차'라는 손실 함수를 미분
한 것과 같다.

변화율은 인공지능 분야에서 특별히 그레이디언트(경사)라고 부른다.

## 04. 선형 회귀를 위한 뉴런을 만듭니다.
### 정방향 계산
예측값을 구한다.
### 역방향 계산
예측값 - 결과값의 음수, 곧 미분한것의 음수

오차가 역전파됩니다.

손실함수를 미분하여 w,b를 구해 최적을 구하는 거다.